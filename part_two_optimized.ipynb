{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2haH_-MUdlnF",
        "outputId": "99b5057b-4288-4706-b28f-aedc6923ac83"
      },
      "outputs": [],
      "source": [
        "\n",
        "# import os\n",
        "\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# os.chdir('/content/drive/MyDrive/School/Howest/TI-AI/Sem3/TrendingTopics/ex1')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0G56cdwdQZM"
      },
      "source": [
        "# Trending Topics in AI\n",
        "Assignment 1: Apply and fine-tune transformer models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mKt7y_xQdQZN",
        "outputId": "ba337b5b-d184-44e3-b8f7-c6187296fcfc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "# Check if GPU is available\n",
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "wu0rmkjrdQZP"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "train_df = pd.read_csv(\"./Recipes_Training.csv\", delimiter=\";\")\n",
        "test_df = pd.read_csv(\"./Recipes_Test.csv\", delimiter=\";\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADG_E2oudQZP"
      },
      "source": [
        "## 1. Load pre-trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "uHu9MI14eso-",
        "outputId": "a064c8a1-59b3-44a9-bf20-edcee08209a2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>cuisine</th>\n",
              "      <th>ingredients</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>25693</td>\n",
              "      <td>southern_us</td>\n",
              "      <td>['plain flour', 'ground pepper', 'salt', 'toma...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>22213</td>\n",
              "      <td>indian</td>\n",
              "      <td>['water', 'vegetable oil', 'wheat', 'salt']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>13162</td>\n",
              "      <td>indian</td>\n",
              "      <td>['black pepper', 'shallots', 'cornflour', 'cay...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3735</td>\n",
              "      <td>italian</td>\n",
              "      <td>['sugar', 'pistachio nuts', 'white almond bark...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>16903</td>\n",
              "      <td>mexican</td>\n",
              "      <td>['olive oil', 'purple onion', 'fresh pineapple...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7995</th>\n",
              "      <td>33556</td>\n",
              "      <td>cajun_creole</td>\n",
              "      <td>['andouille sausage', 'water', 'cajun seasonin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7996</th>\n",
              "      <td>14725</td>\n",
              "      <td>cajun_creole</td>\n",
              "      <td>['black pepper', 'grating cheese', 'all-purpos...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7997</th>\n",
              "      <td>7895</td>\n",
              "      <td>cajun_creole</td>\n",
              "      <td>['fettucine', 'cajun seasoning', 'salt', 'pepp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7998</th>\n",
              "      <td>23661</td>\n",
              "      <td>cajun_creole</td>\n",
              "      <td>['chicken broth', 'crushed tomatoes', 'worcest...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7999</th>\n",
              "      <td>9463</td>\n",
              "      <td>cajun_creole</td>\n",
              "      <td>['dried thyme', 'green onions', 'raisins', 'ga...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8000 rows Ã— 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         id       cuisine                                        ingredients\n",
              "0     25693   southern_us  ['plain flour', 'ground pepper', 'salt', 'toma...\n",
              "1     22213        indian        ['water', 'vegetable oil', 'wheat', 'salt']\n",
              "2     13162        indian  ['black pepper', 'shallots', 'cornflour', 'cay...\n",
              "3      3735       italian  ['sugar', 'pistachio nuts', 'white almond bark...\n",
              "4     16903       mexican  ['olive oil', 'purple onion', 'fresh pineapple...\n",
              "...     ...           ...                                                ...\n",
              "7995  33556  cajun_creole  ['andouille sausage', 'water', 'cajun seasonin...\n",
              "7996  14725  cajun_creole  ['black pepper', 'grating cheese', 'all-purpos...\n",
              "7997   7895  cajun_creole  ['fettucine', 'cajun seasoning', 'salt', 'pepp...\n",
              "7998  23661  cajun_creole  ['chicken broth', 'crushed tomatoes', 'worcest...\n",
              "7999   9463  cajun_creole  ['dried thyme', 'green onions', 'raisins', 'ga...\n",
              "\n",
              "[8000 rows x 3 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jsBUKZ8QdQZP",
        "outputId": "7a1d6e09-4240-4280-c8b8-9f4daaa89f5c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/Harman/gpu-env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "MAX_LEN = 128  # Truncate sequences to 128 tokens\n",
        "train_encodings = tokenizer(list(train_df['ingredients']), truncation=True, padding=True, max_length=MAX_LEN)\n",
        "test_encodings = tokenizer(list(test_df['ingredients']), truncation=True, padding=True, max_length=MAX_LEN)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2nr5nkIdQZQ"
      },
      "source": [
        "## 2. Dataset preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "dvYVfY-1dQZQ"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-kvDc_gdQZR",
        "outputId": "5b1aa5e6-96b1-4f6c-f91a-8e24bec1feea"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['cajun_creole', 'chinese', 'french', 'indian', 'italian',\n",
              "       'mexican', 'southern_us', 'thai'], dtype=object)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Convert the list of ingredients to a string for each row\n",
        "train_df[\"ingredients_str\"] = train_df[\"ingredients\"].apply(lambda x: \" \".join(eval(x)))\n",
        "test_df[\"ingredients_str\"] = test_df[\"ingredients\"].apply(lambda x: \" \".join(eval(x)))\n",
        "\n",
        "# Encode the cuisine label using LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "train_df[\"label\"] = label_encoder.fit_transform(train_df[\"cuisine\"])\n",
        "test_df[\"label\"] = label_encoder.transform(test_df[\"cuisine\"])\n",
        "\n",
        "# Check the label encoding\n",
        "label_encoder.classes_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFDOEQHPdQZR"
      },
      "source": [
        "## 3. Dataset preparing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "g2iPrW3ndQZR"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "LlBLivKddQZR"
      },
      "outputs": [],
      "source": [
        "class CuisineDataset(Dataset):\n",
        "\tdef __init__(self, df, tokenizer, max_len):\n",
        "\t\tself.ingredients = df[\"ingredients_str\"].values\n",
        "\t\tself.labels = df[\"label\"].values\n",
        "\t\tself.tokenizer = tokenizer\n",
        "\t\tself.max_len = max_len\n",
        "\n",
        "\tdef __len__(self):\n",
        "\t\treturn len(self.ingredients)\n",
        "\n",
        "\tdef __getitem__(self, idx):\n",
        "\t\tingredient = self.ingredients[idx]\n",
        "\t\tlabel = self.labels[idx]\n",
        "\n",
        "\t\tencoding = self.tokenizer.encode_plus(\n",
        "\t\t\tingredient,\n",
        "\t\t\ttruncation=True,\n",
        "\t\t\tadd_special_tokens=True,\n",
        "\t\t\tmax_length=self.max_len,\n",
        "\t\t\treturn_token_type_ids=False,\n",
        "\t\t\tpadding=\"max_length\",\n",
        "\t\t\treturn_attention_mask=True,\n",
        "\t\t\treturn_tensors=\"pt\",\n",
        "\t\t)\n",
        "\n",
        "\t\treturn {\n",
        "\t\t\t\"input_ids\": encoding[\"input_ids\"].flatten(),\n",
        "\t\t\t\"attention_mask\": encoding[\"attention_mask\"].flatten(),\n",
        "\t\t\t\"label\": torch.tensor(label, dtype=torch.long)\n",
        "\t\t}\n",
        "\n",
        "MAX_LEN = 128\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# Create the datasets\n",
        "train_dataset = CuisineDataset(train_df, tokenizer, MAX_LEN)\n",
        "test_dataset = CuisineDataset(test_df, tokenizer, MAX_LEN)\n",
        "\n",
        "# Create the dataloaders\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8EznajIGdQZS"
      },
      "source": [
        "## 4. Fine-tune a Pre-trained Transformer Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "jOJUcxiQdQZS"
      },
      "outputs": [],
      "source": [
        "from transformers import BertForSequenceClassification, AdamW\n",
        "from torch.optim import Adam\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGLfrhQSdQZS",
        "outputId": "ba817d22-6ac2-4c03-dc56-4857555a051f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=len(label_encoder.classes_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hCMqZYwcdQZS",
        "outputId": "7db5566c-4e37-4d51-d6c7-2e4ec53d6af6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "# Move the model to the GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ff4iEJypdQZS",
        "outputId": "236ded54-9501-4278-98fa-f836acfa77c8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/Harman/gpu-env/lib/python3.11/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Set up the optimizer and loss function\n",
        "optimizer = AdamW(model.parameters(), lr=1e-5)\n",
        "loss_fn = CrossEntropyLoss().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "krCSInoXhuLU"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "gradient_accumulation_steps = 1\n",
        "num_epochs = 3\n",
        "\n",
        "# Define the optimizer\n",
        "optimizer = optim.AdamW(model.parameters(), lr=1e-5)\n",
        "\n",
        "# Calculate total steps\n",
        "total_steps = len(train_dataloader) // gradient_accumulation_steps * num_epochs\n",
        "\n",
        "# Define the scheduler\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=int(0.1 * total_steps),  # 10% of total steps for warm-up\n",
        "    num_training_steps=total_steps\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lefnf8eVdQZT"
      },
      "source": [
        "## 5. Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGufWMKodQZT",
        "outputId": "a9b983bc-9681-4757-83e9-9f0b2e1aea44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 32/8000"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_2316/2727109943.py:17: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Mixed precision training\n",
            "/tmp/ipykernel_2316/2727109943.py:45: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 8000/8000"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_2316/2727109943.py:71: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Validation Loss: 1.6617402576264881\n",
            "Batch 8000/8000Epoch 2, Validation Loss: 0.9207031007796999\n",
            "Batch 8000/8000Epoch 3, Validation Loss: 0.7023507981073289\n",
            "Batch 8000/8000Epoch 4, Validation Loss: 0.6299618009536986\n",
            "Batch 8000/8000Epoch 5, Validation Loss: 0.6087878090994698\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "import torch.optim as optim\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "num_epochs = 5\n",
        "gradient_accumulation_steps = 4\n",
        "step = 0\n",
        "validation_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "early_stopping = True\n",
        "patience = 2  # Number of epochs to wait before early stopping\n",
        "epochs_no_improve = 0\n",
        "best_validation_loss = float('inf')\n",
        "\n",
        "scaler = GradScaler()  # Mixed precision training\n",
        "\n",
        "# Define the optimizer\n",
        "optimizer = optim.AdamW(model.parameters(), lr=1e-5)\n",
        "\n",
        "# Calculate total steps\n",
        "total_steps = len(train_dataloader) // gradient_accumulation_steps * num_epochs\n",
        "\n",
        "# Define the scheduler\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "\toptimizer,\n",
        "\tnum_warmup_steps=int(0.1 * total_steps),  # Warm-up for 10% of the steps\n",
        "\tnum_training_steps=total_steps\n",
        ")\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "\tmodel.train()\n",
        "\ttotal_loss = 0\n",
        "\n",
        "\tfor batch_idx, batch in enumerate(train_dataloader):\n",
        "\t\t# Calculate current sample index\n",
        "\t\tcurrent_sample = batch_idx * train_dataloader.batch_size + len(batch[\"input_ids\"])\n",
        "\n",
        "\t\t# Calculate the progress\n",
        "\t\tsys.stdout.write(f'\\rBatch {current_sample}/{len(train_dataloader.dataset)}')\n",
        "\t\tsys.stdout.flush()\n",
        "\n",
        "\t\t# Do not zero gradients here; we accumulate them\n",
        "\t\twith autocast():\n",
        "\t\t\toutputs = model(\n",
        "\t\t\t\tinput_ids=batch['input_ids'].to(device),\n",
        "\t\t\t\tattention_mask=batch['attention_mask'].to(device),\n",
        "\t\t\t\tlabels=batch['label'].to(device)\n",
        "\t\t\t)\n",
        "\t\t\tloss = outputs.loss / gradient_accumulation_steps\n",
        "\n",
        "\t\t# Scaled backward for mixed precision\n",
        "\t\tscaler.scale(loss).backward()\n",
        "\n",
        "\t\t# Gradient accumulation and scaler step\n",
        "\t\tif (step + 1) % gradient_accumulation_steps == 0:\n",
        "\t\t\tscaler.step(optimizer)\n",
        "\t\t\tscaler.update()\n",
        "\t\t\toptimizer.zero_grad()\n",
        "\t\t\tscheduler.step()\n",
        "\n",
        "\t\ttotal_loss += loss.item()\n",
        "\t\tstep += 1  # Increment step\n",
        "\n",
        "\t# Validation step\n",
        "\tmodel.eval()\n",
        "\tvalidation_loss = 0\n",
        "\twith torch.no_grad():\n",
        "\t\tfor batch in validation_dataloader:\n",
        "\t\t\twith autocast():\n",
        "\t\t\t\toutputs = model(\n",
        "\t\t\t\t\tinput_ids=batch['input_ids'].to(device),\n",
        "\t\t\t\t\tattention_mask=batch['attention_mask'].to(device),\n",
        "\t\t\t\t\tlabels=batch['label'].to(device)\n",
        "\t\t\t\t)\n",
        "\t\t\t\tloss = outputs.loss\n",
        "\t\t\t\tvalidation_loss += loss.item()\n",
        "\tvalidation_loss /= len(validation_dataloader)\n",
        "\n",
        "\tprint(f'Epoch {epoch+1}, Validation Loss: {validation_loss}')\n",
        "\n",
        "\t# Early stopping logic\n",
        "\tif validation_loss < best_validation_loss:\n",
        "\t\tbest_validation_loss = validation_loss\n",
        "\t\tepochs_no_improve = 0  # Reset counter\n",
        "\t\t# Optionally save the best model here\n",
        "\telse:\n",
        "\t\tepochs_no_improve += 1\n",
        "\n",
        "\tif early_stopping and epochs_no_improve >= patience:\n",
        "\t\tprint('Stopping early due to no improvement in validation loss')\n",
        "\t\tbreak\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQMFmND1dQZU"
      },
      "source": [
        "## 6. Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KaMXoI6gdQZU",
        "outputId": "7cb882c2-5098-480e-def6-bd409659b2a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.8230000000000001, Test Loss: 0.608774221132672, Test F1 Score: 0.8227180229336245\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "\n",
        "def eval_model(model, data_loader, loss_fn, device):\n",
        "\tmodel.eval()\n",
        "\tcorrect_predictions = 0\n",
        "\ttotal_loss = 0\n",
        "\n",
        "\tall_preds = []\n",
        "\tall_labels = []\n",
        "\n",
        "\twith torch.no_grad():\n",
        "\t\tfor batch in data_loader:\n",
        "\t\t\tinput_ids = batch['input_ids'].to(device)\n",
        "\t\t\tattention_mask = batch['attention_mask'].to(device)\n",
        "\t\t\tlabels = batch['label'].to(device)\n",
        "\n",
        "\t\t\toutputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "\t\t\tloss = outputs.loss\n",
        "\t\t\tlogits = outputs.logits\n",
        "\n",
        "\t\t\ttotal_loss += loss.item()\n",
        "\n",
        "\t\t\t_, preds = torch.max(logits, dim=1)\n",
        "\t\t\tcorrect_predictions += torch.sum(preds == labels)\n",
        "\n",
        "\t\t\t# Store predictions and labels for F1 score calculation\n",
        "\t\t\tall_preds.extend(preds.cpu().numpy())\n",
        "\t\t\tall_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "\t# Calculate accuracy\n",
        "\taccuracy = correct_predictions.double() / len(data_loader.dataset)\n",
        "\n",
        "\t# Calculate F1 score\n",
        "\tf1 = f1_score(all_labels, all_preds, average='weighted')\n",
        "\n",
        "\treturn accuracy, total_loss / len(data_loader), f1\n",
        "\n",
        "\n",
        "\n",
        "test_acc, test_loss, test_f1 = eval_model(model, test_dataloader, loss_fn, device)\n",
        "print(f'Test Accuracy: {test_acc}, Test Loss: {test_loss}, Test F1 Score: {test_f1}')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
